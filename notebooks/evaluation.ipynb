{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to evaluate model performance\n",
    "Looking at the performance of a model on the 30 test images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import sys \n",
    "sys.path.append('../src/')\n",
    "from data_process import *\n",
    "from u2net import *\n",
    "from unet import *\n",
    "from resnest import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the evaluation functions\n",
    "def CON_matrix(ref_mask, pred_mask):\n",
    "    \"\"\"Computes the confusion matrix between a reference mask and a predicted mask.\n",
    "\n",
    "    Args:\n",
    "        ref_mask (ndarray): the reference mask\n",
    "        pred_mask (ndarray): the predicted mask\n",
    "\n",
    "    Returns:\n",
    "        ndarray: the confusion matrix\n",
    "    \"\"\"\n",
    "    true = ref_mask.reshape(-1)\n",
    "    pred = pred_mask.reshape(-1)\n",
    "    hist = confusion_matrix(true, pred)\n",
    "    \n",
    "    return hist\n",
    "\n",
    "def Pixel_Accuracy(hist):\n",
    "    \"\"\"Calculates the pr pixel accuracy.\"\"\"\n",
    "    # acc = (TP + TN) / (TP + TN + FP + TN)\n",
    "    acc = np.diag(hist).sum() / hist.sum()\n",
    "    return acc\n",
    "\n",
    "def Mean_Pixel_Accuracy(hist):\n",
    "    \"\"\"Calculates the mean pixel accuracy.\"\"\"\n",
    "    # acc = (TP) / TP + FP\n",
    "    acc = np.diag(hist) /  hist.sum(1)\n",
    "    mean_Acc = np.nanmean(acc)\n",
    "    return mean_Acc\n",
    "\n",
    "def MIOU(hist):\n",
    "    \"\"\"Calculates the mean IOU.\"\"\"\n",
    "    sum = np.mean(np.diag(hist) / (hist.sum(1) + hist.sum(0) - np.diag(hist)))\n",
    "    return sum\n",
    "\n",
    "def evaluate(model, device, test_array):\n",
    "    \"\"\"Function to evaluate a model on the test set. Return the mean IOU, mean pixel accuracy and pixel accuracy.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): a trained model (U-Net, U^2-Net, ResNeSt)\n",
    "        device (torch.device): device to run the model on\n",
    "        test_array (np.array): numpy array holding the test dataset\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    sum_miou = 0\n",
    "    sum_mean_acc = 0\n",
    "    sum_acc = 0\n",
    "    for array in test_array:\n",
    "        mask = array[:,:,3]\n",
    "        imgA = array[:,:,0:3]\n",
    "\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                            std=[0.229, 0.224, 0.225])])\n",
    "        imgA = transform(imgA)\n",
    "        imgA = imgA.to(device)      \n",
    "        imgA = imgA.unsqueeze(0)\n",
    "        \n",
    "        if model.name == \"U2NET\":\n",
    "            prediction, _,_,_,_,_,_ = model(imgA)\n",
    "        else:\n",
    "            prediction = model(imgA)\n",
    "\n",
    "        pred_np = prediction.cpu().detach().numpy().copy()  # pred_np.shape = (1, 10, 256, 256)\n",
    "        pred_np = (np.argmax(pred_np, axis=1) * 10).astype(np.uint8)\n",
    "        hist = CON_matrix(mask, pred_np[0])\n",
    "        sum_miou = MIOU(hist) + sum_miou\n",
    "        sum_mean_acc = Mean_Pixel_Accuracy(hist) + sum_mean_acc\n",
    "        sum_acc = Pixel_Accuracy(hist) + sum_acc\n",
    "    \n",
    "    mean_miou = sum_miou / test_array.shape[0]\n",
    "    mean_acc = sum_mean_acc / test_array.shape[0]\n",
    "    acc = sum_acc / test_array.shape[0]\n",
    "    \n",
    "    return mean_miou, mean_acc, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_345404/1383575292.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = np.diag(hist) /  hist.sum(1)\n",
      "/tmp/ipykernel_345404/1383575292.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = np.diag(hist) /  hist.sum(1)\n",
      "/tmp/ipykernel_345404/1383575292.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = np.diag(hist) /  hist.sum(1)\n",
      "/tmp/ipykernel_345404/1383575292.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = np.diag(hist) /  hist.sum(1)\n",
      "/tmp/ipykernel_345404/1383575292.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = np.diag(hist) /  hist.sum(1)\n",
      "/tmp/ipykernel_345404/1383575292.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = np.diag(hist) /  hist.sum(1)\n",
      "/tmp/ipykernel_345404/1383575292.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = np.diag(hist) /  hist.sum(1)\n",
      "/tmp/ipykernel_345404/1383575292.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = np.diag(hist) /  hist.sum(1)\n",
      "/tmp/ipykernel_345404/1383575292.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = np.diag(hist) /  hist.sum(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IOU: 0.4855293261939275\n",
      "Mean Pixel Accuracy: 0.6210484732327283\n",
      "Pixel Accuracy: 0.8663412729899088\n"
     ]
    }
   ],
   "source": [
    "# Load the test dataset\n",
    "# test_array = np.load(\"../data/test3_arr.npy\")   # path to original ground truth\n",
    "test_array = np.load(\"../data/good_test_arr.npy\") # path were bad ground truth is removed\n",
    "\n",
    "# Load the model to be evaluated\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torch.load(\"../trained_models/resnest101/ade1-4_d05_b6_e100/ResNeSt101_50_loss_trian_0.0183_val_0.01608.pt\", map_location=device)\n",
    "# Evaluate\n",
    "miou, mean_acc, acc = evaluate(model, device, test_array)\n",
    "print(f\"Mean IOU: {miou}\")\n",
    "print(f\"Mean Pixel Accuracy: {mean_acc}\")\n",
    "print(f\"Pixel Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best so far\n",
    "**Model**: resnest50/ad1e-4_d08_b3_e250/ResNeSt50_130_loss_trian_0.02333_val_0.01631.pt\n",
    "\n",
    "Goodtest:\n",
    "```\n",
    "Mean IOU: 0.5111849011853413\n",
    "Mean Pixel Accuracy: 0.6279514596907317\n",
    "Pixel Accuracy: 0.8778921763102213\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
